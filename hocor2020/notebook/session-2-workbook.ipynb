{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[HOCOR 2020] Corpus_indexing_workbook.ipynb","provenance":[{"file_id":"1o1WH0U_zyfjhouzzvEU8G8iDo915xNfY","timestamp":1607067411294}],"collapsed_sections":[],"authorship_tag":"ABX9TyNsKqsZDdp57nQ5NECvT5cE"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"J-PQ591NpQtb"},"source":["# 這堂課的任務\n","  * Step 0: 引入會用到的套件\n","  * Step 1: 下載語料檔 (語料已經過斷詞前處理)\n","  * Step 2: 將語料讀進來\n","  * Step 3: 觀察語料\n","  * Step 4: 對語料進行 Indexing\n","  * Step 5: 實作 Concordance\n","  * Step 6: 實作 Collocation\n","  \n","  > 迷路時的提醒：請記得真實世界中的例子，你現在手上有一本小說 (Step 0 - 3)，小說的最後還沒有任何Index，所以我們首先要進行 Indexing (Step 4)，產生出 Index 後 ，我們要利用這個 Index 做查詢 (Step 5, 6)。"]},{"cell_type":"markdown","metadata":{"id":"n6g_lf9XqP0L"},"source":["# Step 0: 引入會用到的套件"]},{"cell_type":"code","metadata":{"id":"7Avb92lqoh3I"},"source":["# 用來讀取以json格式儲存的語料檔 [Step 2]\n","import json\n","\n","# defaultdict 用來方便進行 indexing\n","# Counter 用來方便統計各版文章數\n","# [Step 3, 4]\n","from collections import defaultdict, Counter \n","\n","# 用來計算程式執行時間 [Step 5]\n","import time\n","\n","# 用來對 token 做 regular expression 查詢 [Step 5]\n","import re\n","\n","# 用來顯示美美的查詢結果 [Step 5]\n","import tabulate\n","import pandas as pd\n","from IPython.display import HTML, display\n","\n","%load_ext google.colab.data_table"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WR_BYupWbp5B"},"source":["# Step 1: 下載語料檔"]},{"cell_type":"code","metadata":{"id":"Ad6WvkF_hFiW"},"source":["# 用來下載 Google Drive 文件的 Python 套件\n","# Colab 已內建此指令\n","!pip install gdown"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pYrY4_6Kbr-1"},"source":["!gdown --id \"1mmAdISiVBw_acDRiyoAFFOIJoyDQ6dPa\" -O \"dcard2.jsonl\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EPfVUfWAeuFL"},"source":["# TODO: 看 dcard2.jsonl 的前五行\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_2JGxxO6G-RL"},"source":["<a href=\"https://drive.google.com/file/d/1Yp4501Db7Dyj_gJg0f107FnTDg2ohhhw/view?usp=sharing\" _target=\"blank\"><img src=\"https://drive.google.com/uc?id=1Yp4501Db7Dyj_gJg0f107FnTDg2ohhhw\" width=\"400\"></a>"]},{"cell_type":"markdown","metadata":{"id":"dt5AwoBdeg1c"},"source":["觀察：我們的語料中，有什麼 metadata 和 data?"]},{"cell_type":"markdown","metadata":{"id":"PW4AWdHcPgVr"},"source":["# Step 2: 將語料讀進來"]},{"cell_type":"code","metadata":{"id":"1g0ifpXzoUsu"},"source":["RAW_DATA_PATH = \"dcard2.jsonl\"\n","\n","# 用一個空的 list 準備裝進語料\n","corpus = []\n","\n","# TODO: 將每行 json 一一讀進 corpus\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AXMtog4lXdOs"},"source":["<a href=\"https://drive.google.com/file/d/1KR9XvKZS1sgGtS_Eqo91-vAUOdDrkh5W/view?usp=sharing\" _target=\"blank\"><img src=\"https://drive.google.com/uc?id=1KR9XvKZS1sgGtS_Eqo91-vAUOdDrkh5W\" width=\"900\"></a>\n"]},{"cell_type":"markdown","metadata":{"id":"iVchZwxTP746"},"source":["# Step 3: 觀察語料"]},{"cell_type":"markdown","metadata":{"id":"-n8y3Ct-obc2"},"source":["## 3-0: 認識語料的資料結構"]},{"cell_type":"code","metadata":{"id":"nhs6IgSgQIkV"},"source":["# TODO: 查看總文章篇數\n","# 因為 corpus 是一個 list，我們剛剛把每篇文章一一加入這個 list\n","# 所以用 len() 去讀取這個 list 的長度，就是去看我們總共有幾篇文章\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BJI0OFZxQBP8"},"source":["# TODO: 查看語料中的第零篇文章內容\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Um0hrdDyhnuE"},"source":["# TODO: 查看第零篇文章的版名\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y-gD7Btug-iB"},"source":["# TODO: 查看第零篇文章中的第零個句子\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JE-PwOiah5lt"},"source":["# TODO: 查看第零篇文章中的第零個句子中的第零個token\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Csp5OIRiNN7"},"source":["# TODO: 查看第零篇文章中的第零篇句子中的第零篇token的詞目是什麼\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8z-mMFhsYQkW"},"source":["<a href=\"https://drive.google.com/file/d/1SCPNqwhftuRLHI7jd-l7xEc620kZRjNC/view?usp=sharing\" _target=\"blank\"><img src=\"https://drive.google.com/uc?id=1SCPNqwhftuRLHI7jd-l7xEc620kZRjNC\" width=\"900\"></a>"]},{"cell_type":"markdown","metadata":{"id":"b1HRIUZfzoQ8"},"source":["`corpus` 是我們用來儲存語料的地方，由於我們可以餵位置給`corpus`，讓`corpus`告訴我們該位置的詞是什麼。在這個意義下，`corpus`其實就是一個 Foward Index (正向索引)。"]},{"cell_type":"markdown","metadata":{"id":"bFQAp-VMih3R"},"source":["## 3-1: 觀察 metadata"]},{"cell_type":"code","metadata":{"id":"gaUOFyQJilE3"},"source":["# TODO: 看我們的語料中到底有哪些版，以及每個版各有幾篇文章\n","#       請讓 forum 這個變數的內容最後的結果如下圖\n","# 我們將以 collections.Counter 來達成這個目標\n","# 使用前要先引入: from collections import Counter\n","forum = Counter()\n","\n","# 請接著完成版名的統計\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XT7StQDaofMk"},"source":["<a href=\"https://drive.google.com/file/d/17WIpNn8m_7UPyjHXOSlJ331v51Jtknzm/view?usp=sharing\" _target=\"blank\"><img src=\"https://drive.google.com/uc?id=17WIpNn8m_7UPyjHXOSlJ331v51Jtknzm\" width=\"400\"></a>"]},{"cell_type":"code","metadata":{"id":"DW60EUj8QIGE"},"source":["# TODO: 看一下 forum 長什麼樣子\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AEVB86L7Ty1h"},"source":["# TODO: 叫出前十多文章的版\n","# 請使用 Counter.most_common()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZzYyV-yAPrHp"},"source":["# Step 4: 對語料進行 Indexing (重頭戲🎪)\n","\n","想像你是一個機器人，現在我丟給你一本斷好詞的「哈利波特：阿茲卡班的逃犯」，\n","\n","請你幫我產生一個可以附在最後面的索引，好讓讀者可以去查「妙麗」出現的地方。\n","\n","這時你會怎麼做？"]},{"cell_type":"markdown","metadata":{"id":"WwzfVSzLsh-A"},"source":["## 4-0: 暖身操: 利用 `enumerate()` 取得list中的位置訊息"]},{"cell_type":"code","metadata":{"id":"M38IinYGt4J0"},"source":["s = [\"今天\", \"天氣\", \"晴\"]\n","\n","for element in s:\n","    print(element)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_0lUF87BuCce"},"source":["# TODO: 請使用 enumerate() 在印出 list 當中的每個元素的同時，也一併印出該元素的 index\n","# 範例輸出：\n","# 0 今天\n","# 1 天氣\n","# 2 晴"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cn-acsxWshNg"},"source":["# 假設我們今天有一個更複雜的語料結構（與我們的語料結構雷同）\n","\n","fake_corpus = [\n","    # article 0\n","    [\n","        # setence 0\n","        [\n","            {\"word\": \"這\", \"pos\": \"NH\"},     # token 0\n","            {\"word\": \"是\", \"pos\": \"SHI\"},    # token 1\n","            {\"word\": \"第\", \"pos\": \"N\"},      # token 2\n","            {\"word\": \"零\", \"pos\": \"X\"},      # ...\n","            {\"word\": \"句\", \"pos\": \"X\"},\n","         \n","        ],\n","        # sentence 1\n","        [\n","            {\"word\": \"這\", \"pos\": \"NH\"},\n","            {\"word\": \"是\", \"pos\": \"SHI\"},\n","            {\"word\": \"第\", \"pos\": \"N\"},\n","            {\"word\": \"一\", \"pos\": \"X\"},\n","            {\"word\": \"句\", \"pos\": \"X\"},\n","        ],\n","    ],\n","\n","    # article 1\n","    [\n","        # sentence 0\n","        [\n","            {\"word\": \"另\", \"pos\": \"NH\"},\n","            {\"word\": \"一\", \"pos\": \"SHI\"},\n","            {\"word\": \"篇\", \"pos\": \"N\"},\n","            {\"word\": \"文章\", \"pos\": \"X\"},\n","        ],\n","    ]\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KFXzCuJUgnXX"},"source":["# TODO: 請用迴圈取出每一個token的詞目(word)，讓輸出的每行是一個單獨的token詞目\n","# 範例輸出:\n","# 這\n","# 是\n","# 第\n","# 零\n","# 句\n","# 這\n","# 是\n","# 第\n","# 一\n","# 句\n","# 另\n","# 一\n","# 篇\n","# 文章\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N1UNAwWHuxHU"},"source":["# TODO: 那要如何搭配 enumerate() 才能給出每一個詞目所在的 文章id, 句子id, token id 呢？\n","# 範例輸出:\n","# 0 0 0 這\n","# 0 0 1 是\n","# 0 0 2 第\n","# 0 0 3 零\n","# 0 0 4 句\n","# 0 1 0 這\n","# 0 1 1 是\n","# 0 1 2 第\n","# 0 1 3 一\n","# 0 1 4 句\n","# 1 0 0 另\n","# 1 0 1 一\n","# 1 0 2 篇\n","# 1 0 3 文章\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AqkxXsURZv0A"},"source":["## 4-1: 對詞目進行Indexing"]},{"cell_type":"code","metadata":{"id":"ajaZxDkZokiz"},"source":["word_index = {}    # 用來儲存詞目的索引\n","\n","# TODO: 請用 4-0 所提到的方法，對 corpus 做讀取，並讓 word_index 最後的結果如下圖\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hm1aWHcojZqW"},"source":["<a href=\"https://drive.google.com/file/d/1a7bs6Pux1CINo1ONGf_C0DW6aRXSgSkO/view?usp=sharing\" _target=\"blank\"><img src=\"https://drive.google.com/uc?id=1a7bs6Pux1CINo1ONGf_C0DW6aRXSgSkO\" width=\"400\"></a>"]},{"cell_type":"markdown","metadata":{"id":"a_Rq-1bNvrIN"},"source":["## 4-2: 換個方式對詞性做Indexing\n","\n","使用 Python 提供給我們的捷徑: `defaultdict`\n","\n","要先 import 進來才能使用:\n","```python\n","from collections import defaultdict\n","```"]},{"cell_type":"code","metadata":{"id":"7DwkJItSaB5j"},"source":["pos_index = defaultdict(list)     # 用來儲存詞性的索引\n","\n","# 對 dcard2.jsonl 中的每一行進行讀取。每一行就是一篇貼文。\n","for article_idx, article in enumerate(corpus):\n","    for sentence_idx, sentence in enumerate(article['text']):\n","        for token_idx, token in enumerate(sentence):\n","            \n","            locator = [article_idx, sentence_idx, token_idx]\n","\n","            # 使用 defaultdict 的方便之處在於\n","            # 這裡我們就不用多做 4-1 中所做的判斷\n","            # defaultdict 會自動幫我們處理這件事\n","            pos_index[token['pos']].append(locator) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5-fWEMwpVzkW"},"source":["## 4-3: 查看 Indexing 後的結果"]},{"cell_type":"code","metadata":{"id":"i1Gp52aQ9oEl"},"source":["# TODO: 叫出「虐心」這個詞在我們語料中所有出現的地方\n","# 並解讀出現結果的結構/意義是什麼\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8iviHAqUKCNh"},"source":["<a href=\"https://drive.google.com/file/d/1nZ-h8McCSXVrHKqz-hro_dZMjoMefRn5/view?usp=sharing\" _target=\"blank\"><img src=\"https://drive.google.com/uc?id=1nZ-h8McCSXVrHKqz-hro_dZMjoMefRn5\" width=\"400\"></a>"]},{"cell_type":"code","metadata":{"id":"NJjUKaPi2oVb"},"source":["#TODO: 寫一個函數 word_freq(word)\n","#      輸入一個詞，回傳該詞詞頻\n","def word_freq(word):\n","    pass"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tHNmAGlN487-"},"source":["# TODO: 請找出「的」的詞頻\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jxhBo4if27KV"},"source":["#TODO: 寫一個函數 pos_freq(pos)\n","#      輸入一個詞性，回傳該詞性頻率\n","def pos_freq(pos):\n","    pass"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FzD-VB2zpNc-"},"source":["# TODO: 請找出我們語料中word type的數量\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V0qhu--VxYjy"},"source":["# TODO: 請找出我們語料中pos type的數量\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3wUTwcx7xYnD"},"source":["# TODO: 請列出所有的詞性\n","token_sum = 0\n","\n","for word, list_of_locator in word_index.items():\n","    token_sum += word_freq(word)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R1uYr-PJ1a2K"},"source":["詞性意義請參考：\n","- [中研院平衡語料庫詞類標記集](http://ckipsvr.iis.sinica.edu.tw/papers/category_list.pdf)\n","- [中研院詞庫小組. (1993). 中文詞類分析(三版)](https://ckip.iis.sinica.edu.tw/data/paper/report/ckip-9305.pdf)"]},{"cell_type":"code","metadata":{"id":"8E9HaofuodNp"},"source":["# TODO: 請找出我們語料的總token數是多少\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"STjEi59GOxQV"},"source":["## [插曲] 比較有無 index 的時間差"]},{"cell_type":"code","metadata":{"id":"0He058sLO3Sv"},"source":["def compare_time_with_and_without_index(word):\n","\n","    print(f\"查詢的詞: {word}\")\n","    print(f\"該詞於語料庫中的詞頻: {len(word_index[word])}\")\n","\n","\n","    ###### 使用 index: 給時間寶貴的大忙人 ######\n","    t1 = time.time()\n","    for a_idx, s_idx, w_idx in word_index[word]:\n","        pass\n","    t2 = time.time()\n","    t_with_index = t2 - t1\n","    \n","\n","    ###### 不使用 index: 給勤奮的螞蟻 ######\n","    t1 = time.time()\n","    \n","    # TODO: 如果要每次搜尋都要重新掃過一整個語料庫看某詞有沒有出現\n","    pass\n","    \n","    t2 = time.time()\n","    t_without_index = t2 - t1\n","\n","    ###### 不使用index的時間 比上 使用index的時間 ######\n","    ratio = t_without_index / t_with_index\n","    \n","    # 印出結果\n","    print(f\"使用index的時間: {t_with_index:.6f}\")\n","    print(f\"不使用index的時間: {t_without_index:.6f}\")\n","    print(f\"without_index / with_index = {ratio:6f}\")\n","    print(\"-----------\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x-2XA-nqPPQC"},"source":["compare_time_with_and_without_index(\"虐心\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UI4nUAJTPSBj"},"source":["# TODO: 試看看針對不同出現頻率的詞，使用/不使用index的時間差距，並試著解讀為什麼會有這樣的差別。\n","# 比較: 出現 1      次的 \"珍妮\"\n","#      出現 510    次的 \"造成\"\n","#      出現 87610  次的 \"是\" \n","#      出現 231504 次的 \"的\"\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v-LJxswwPQX3"},"source":["為什麼一詞的詞頻越大，使用 index 的效率會越來越接近不使用 index 的效率？ 感受一下，這樣的差距與日常生活中的經驗是否一致？"]},{"cell_type":"markdown","metadata":{"id":"qetySRMRCS4G"},"source":["# Step 5: Concordance\n","\n"]},{"cell_type":"markdown","metadata":{"id":"FrFVaxev3G2v"},"source":["## 5-0: 從 word_index 中搜尋單詞出現的句子"]},{"cell_type":"code","metadata":{"id":"lS8SAIm9PzLe"},"source":["# TODO: 請利用 word_index ，印出所有出現「虐心」一詞的句子\n","#       每個詞目之間請以一個空格隔開\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RrVazYT3oy7n"},"source":["## 5-1: 加進 window_size 的考量"]},{"cell_type":"code","metadata":{"id":"peLxKV_uNGO3"},"source":["# 先以其中一個「虐心」出現的地方為例: [5777, 7, 4]\n","\n","# TODO: 宣告一個變數 sentence，並將 sentence 設為語料中的第 5777 篇文章中的第 7 句\n","sentence = \n","\n","# sentence 是一個 list of tokens\n","print(sentence)    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RPrA-0SxR9oL"},"source":["# TODO: 請列出此句中的每個詞目為何\n","#       每個詞目之間請以一個空格隔開\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DhZGyFcNSZZx"},"source":["# TODO: 請印出此句中「虐心」的前 3 個詞到後 3 個詞 (window_size 為 3)\n","window_size = 3\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VsDdlPH9Vlu2"},"source":["<a href=\"https://drive.google.com/file/d/1RGJzG7SHH_aBZvz0FDK1KBcFwKnSRj4l/view?usp=sharing\" _target=\"blank\"><img src=\"https://drive.google.com/uc?id=1RGJzG7SHH_aBZvz0FDK1KBcFwKnSRj4l\" width=\"400\"></a>"]},{"cell_type":"code","metadata":{"id":"GOwWcyCRSbhG"},"source":["# TODO: 將 window_size 設為 5 看看\n","\n","window_size = 5\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U2dyUoF1Xu9H"},"source":["# 錯誤來自於兩個地方\n","#    (1) (該詞出現的位置 - window_size) 可能會小於 0: 也就是會超出句子左邊的邊界\n","#    (2) (該詞出現的位置 + window_size) 可能會大於 句子長度: 也就是會超出句子右邊的邊界\n","# 所以我們必須設停損點:\n","#    (1) 對左邊邊界而言，如果 (該詞出現的位置 - window_size) < 0 ，那麼就停在 0 數值 => 使用 max(0, (該詞出現的位置 - window_size))\n","#    (2) 對右邊邊界而言，如果 (該詞出現的位置 + window_size) > 句子長度 ，那麼就停在句子長度的數值 => min(句子長度, (該詞出現的位置 + window_size))\n","\n","# TODO: 讓我們來加進安全邊界的考量吧\n","\n","window_size = 100\n","\n","safe_left_bound = pass\n","safe_right_bound = pass\n","\n","for i in range(safe_left_bound, safe_right_bound):\n","  print(sentence[i][\"word\"] + \" \", end=\"\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j7gCDLmdMZtT"},"source":["## 5-2 完成第一個 `query_a_word()` 功能\n","\n","能查詢單個詞目，並按照需求顯示相關資訊。\n","\n","執行範例：\n","```python\n","query_a_word(\"虐心\", window_size=5, show_pos=False, metadata=[\"forumName\", \"likeCount\"])\n","```\n","\n","會回傳\n","```python\n","[ \n","     {\"article_id\": 30, \"left\": \"這部戲真的很\", \"keyword\": \"虐心\", \"right\": \"！\", \"forumName\": \"戲劇\", \"likeCount\": 20 }, # 第0句\n","     {\"article_id\": 33, \"left\": \"真的太\", \"keyword\": \"虐心\", \"right\": \"了吧。\", \"forumName\": \"文學\", \"likeCount\": 20 }, # 第1句\n","     ...\n"," ]\n","```"]},{"cell_type":"code","metadata":{"id":"JJQVX81NCVlq"},"source":["# TODO: 寫一個函式 query_a_word(word, window_size, show_pos), 接收三個參數:\n","#     word: 要搜尋的關鍵字 <字串>\n","#     window_size: 指定視窗大小 <整數>\n","#     show_pos: 是否顯示詞性 <Bool>\n","# 此函數將回傳所有該關鍵字出現的句子，結構為 list of dicts\n","\n","def query_a_word(word, window_size=5, show_pos=False, metadata=[]):\n","\n","    # 最後的結果\n","    results = []\n","\n","    # 從索引中叫出該詞出現的地方，並用迴圈一一處理\n","    \n","\n","        # 該詞出現的某個句子\n","\n","\n","        # 準備好每個要裝進 results 的元素\n","        each_concordance_line = {\n","            \n","        }\n","\n","        # 需要哪些metadata，就把那些metadata裝進來\n","\n","\n","        # 判斷關鍵字是否要顯示詞性\n","\n","\n","        # 安全邊界\n","\n","\n","        # 先處理處理關鍵字的左邊部分\n","\n","\n","        # 再處理處理關鍵字的右邊部分\n"," \n","\n","\n","        # 每次處理完後記得把 each_concordance_line 加進 results 中\n","        results.append(each_concordance_line)\n","\n","    return results"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iBtj5D4Jruo7"},"source":["# TODO: 試著使用 query_a_word() 看看\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e1aGZ6i7r_-_"},"source":["# TODO: 把結果餵給 pd.DataFrame()\n","columns_order = ['article_id', 'forumName', 'likeCount', \"left\", \"keyword\", \"right\"]\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ybWD7Lt8MPS9"},"source":["## 5-3: 重新組織一下巨大的 `query_a_word()`"]},{"cell_type":"markdown","metadata":{"id":"WCq3lY6qMPdM"},"source":["<a href=\"https://drive.google.com/file/d/1qpiJjz6oQOF1w0tMg0O4Wk5QSVvW3VWg/view?usp=sharing\" _target=\"blank\"><img src=\"https://drive.google.com/uc?id=1qpiJjz6oQOF1w0tMg0O4Wk5QSVvW3VWg\" width=\"400\"></a>"]},{"cell_type":"markdown","metadata":{"id":"Sf6h0sQFAlmy"},"source":["`query_a_word()` 裡頭做的事，其實可以分成兩大部分:\n","\n","1. 篩選index: 從 index 中篩選出符合某一個 query 條件的 locator\n"," - 詞目為 \"虐心\"\n"," - 詞性為 \"V\"\n"," - 多詞目並列： \"做\" \"一\" \"個\"\n"," - 詞性, 詞目並列： \"V\" \"起來\"\n","2. 生成一個個的concordance line: 處理顯示結果\n"," - 需不需要顯示詞性？\n"," - 要給出幾個 window_size 的上下文?\n"," - 需要給出哪些metadata?\n","\n","區分這兩大部分的好處，有助於我們之後做更複雜的查詢時，可以更專注地處理程式的不同部分。"]},{"cell_type":"code","metadata":{"id":"dCZxXdWPAoDh"},"source":["def query_a_word(word, window_size=5, show_pos=False, metadata=[]):\n","\n","    results = []\n","\n","    # 在這裡我們用 locator 取代原本的 a_idx, s_idx, t_idx\n","    # 所以現在 locator 就會是一個 list: [a_idx, s_idx, t_idx]\n","    # 我們把開箱 locator 的任務交給 generate_concordance_line()\n","    for locator in filter_a_word(word):       \n","        result = generate_concordance_line(locator, window_size, show_pos, metadata)\n","        results.append(result)\n","\n","    return results\n","\n","\n","def filter_a_word(word):\n","    return word_index[word]\n","\n","\n","def generate_concordance_line(locator, window_size, show_pos, metadata):\n","    a_idx = locator[0]\n","    s_idx = locator[1]\n","    t_idx = locator[2]\n","\n","    sentence = corpus[a_idx]['text'][s_idx]\n","\n","    # 準備好每個元素\n","    each_concordance_line = {\n","        \"article_id\": a_idx,\n","        \"left\": \"\",\n","        \"keyword\": \"\",\n","        \"right\": \"\"\n","    }\n","\n","    # 需要哪些metadata，就把那些metadata裝進來\n","    for key in metadata:\n","        each_concordance_line[key] = corpus[a_idx][key]\n","\n","    # 判斷是否要顯示詞性\n","    if show_pos:\n","        each_concordance_line[\"keyword\"] = sentence[t_idx][\"word\"] + \"/\" + sentence[t_idx][\"pos\"]\n","    else:\n","        each_concordance_line[\"keyword\"] = sentence[t_idx][\"word\"]\n","\n","    # 安全邊界\n","    safe_left_bound = max(0, t_idx - window_size)\n","    safe_right_bound = min(len(sentence), t_idx + window_size + 1)\n","\n","\n","    # 先處理處理關鍵字的左邊部分\n","    for token in sentence[safe_left_bound: t_idx]:\n","        if show_pos:\n","            each_concordance_line[\"left\"] += token[\"word\"] + \"/\" + token[\"pos\"]\n","        else:\n","            each_concordance_line[\"left\"] += token[\"word\"]\n","\n","    # 再處理處理關鍵字的右邊部分\n","    for token in sentence[t_idx + 1: safe_right_bound]:\n","        if show_pos:\n","            each_concordance_line[\"right\"] += token[\"word\"] + \"/\" + token[\"pos\"]\n","        else:\n","            each_concordance_line[\"right\"] += token[\"word\"]\n","\n","    return each_concordance_line\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B2Wcp045kI31"},"source":["## 5-4: 美美的資料，閱讀舒適度提升"]},{"cell_type":"markdown","metadata":{"id":"dGJvtN6y_NBf"},"source":["1. 資料與資料呈現\n","2.  閱讀版面舒適度調整"]},{"cell_type":"markdown","metadata":{"id":"Bz22dmfVyLZA"},"source":["<a href=\"https://drive.google.com/file/d/1sNPMBGdCMGTiqKunsYpAw0r3BdhQQalL/view\" target=\"_blank\"><img src=\"https://drive.google.com/u/0/uc?id=1sNPMBGdCMGTiqKunsYpAw0r3BdhQQalL&export=download\" width=\"85%\"></a>"]},{"cell_type":"markdown","metadata":{"id":"oSFka_YC0RV7"},"source":["> 關於資料呈現的想像：直接面對海量資料就好像\b近視沒戴眼鏡，或是去看 3D 電影不帶特製眼鏡一樣，好像有東西在那裡卻又好模糊、不確知那是什麼或是傳達了什麼。"]},{"cell_type":"markdown","metadata":{"id":"yF4BgWIFCokI"},"source":["資料視覺化的工具 ( [Charting in Colaboratory](https://colab.research.google.com/notebooks/charts.ipynb#scrollTo=QSMmdrrVLZ-N)  )\n","\n","- [Matplotlib](https://matplotlib.org/) : the most common charting package. \n","- [Seaborn](http://seaborn.pydata.org/) : One of several libraries layered on top of Matplotlib that is worth highlighting, and you can use in Colab. (Colaboratory charts use Seaborn's custom styling by default.)\n","- [Altair](https://altair-viz.github.io/) : a declarative visualization library for creating interactive visualizations in Python, and is installed and enabled in Colab by default. \n"]},{"cell_type":"markdown","metadata":{"id":"x2oothkoCvTh"},"source":["### 5-4-0: 若是「文字資料」的呈現呢？\n","\n","<img src=\"https://drive.google.com/u/0/uc?id=1KultyJIj4cGq6E9LhF0tHLTRo_7073E3&export=download\" width=\"50%\">\n","\n","\n","> 適合一直放在心上的探問：要怎傳達(資料)會是最有效、直覺的？"]},{"cell_type":"markdown","metadata":{"id":"CZsora-2ppXD"},"source":["### 5-4-1: [python-tabulate](https://pypi.org/project/tabulate/) \n","\n","- 輕鬆印出表格：只要呼叫一個 function 就能完成！\n","- 將輕量純文本轉為表格數據：具多種輸出格式供後續編輯與轉換\n","- 混合的文本與數據資料也能很好讀：欄位對齊、數字格式\n"]},{"cell_type":"code","metadata":{"id":"tk83SYPqySnq"},"source":["# 感覺一下使用 python-tabulate 呈現資料\n","from tabulate import tabulate"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"quRvGYKFyWVq"},"source":["table = [[\"Sun\",696000,1989100000],[\"Earth\",6371,5973.6],[\"Moon\",1737,73.5],[\"Mars\",3390,641.85]]\n","\n","print(table)\n","print(tabulate(table, headers=[\"Planet\",\"R (km)\", \"mass (x 10^29 kg)\"]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FLx8PoTFygyq"},"source":["print(tabulate(result_nuexin, headers=\"keys\", showindex=\"always\", tablefmt=\"simple\"))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yjZvjMr4GUq1"},"source":["當資料不只有 10 筆時，看起來會怎麼樣呢？"]},{"cell_type":"code","metadata":{"id":"UHZV_Ap8xk4h"},"source":["result_yen = query_a_word(\"語言\", 10)\n","\n","print(tabulate(result_yen, headers=\"keys\", showindex=\"always\", tablefmt=\"simple\"))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T4Gp8FpZnu07"},"source":["### 5-4-2: [pandas](https://pandas.pydata.org/docs/user_guide/index.html)\n","\n","- 讀取表格數據(tabular data)資料的超實用工具\n","- 資料類型：Series(一維) ＆ DataFrame(二維, 很常用)\n","- 直接看 [Cheat Sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf) 了解更多\n"]},{"cell_type":"code","metadata":{"id":"E-PJPUoXG6ll"},"source":["# 使用 pandas 中的 pd.DataFrame() 的結果\n","import pandas as pd\n","\n","pd.DataFrame(result_nuexin)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QhXJ6gHqtiWu"},"source":["#TODO: 請大家使用 query_a_word() 查詢「語言」，並把結果餵給 pd.DataFrame()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9jvGzD4dcdRq"},"source":["pd.DataFrame(query_a_word(\"是\", 10), columns=columns_order)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bA6PzIQHatz1"},"source":["> 資料筆數多（87610 筆），但是看不到全部 >>> 有更好的呈現方式嗎？互動的可能性？"]},{"cell_type":"markdown","metadata":{"id":"1w-x8KyzHTfk"},"source":["### 5-4-3: [Data Table Display](https://colab.research.google.com/notebooks/data_table.ipynb)  \n","\n","- 互動性呈現：篩選、分類、分頁設定等\n","- 可客製化"]},{"cell_type":"code","metadata":{"id":"OZwo1cLoq7Ha"},"source":["# 加入 Data Table Display extension\n","# renders pandas dataframes into interactive displays that can be filtered, sorted, and explored dynamically\n","\n","%load_ext google.colab.data_table"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wkLO5mGqm-vD"},"source":["pd.DataFrame(result_nuexin)\n","\n","#TODO: 選出按讚數為 50~100 之間的資料\n","\n","#TODO: 找出包含「...」、「》」、「〖 〗」的資料\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_RWWHvhwkjNK"},"source":["# 直接生成 data tables \n","from google.colab import data_table\n","\n","# 可使用參數達到更多客製化的呈現\n","data_table.DataTable(pass)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LJkGF3Q8IpE8"},"source":["### 5-4-4: 天哪，我把資料變好看了！ \n","\n","#### 玩美步驟\n","\n","1. 在網頁上按右鍵 \n","2. 選擇「檢查」 來看 html 程式碼 \n","3. 找到我們的目標區段（css selector）\n","4. 寫 css code 來改變「對齊方式」、「顏色」\n","5. 資料更好看了！（得到美美的 corpus 資料呈現格式）"]},{"cell_type":"markdown","metadata":{"id":"SJZbApBWTSCG"},"source":["html 圖解\n","\n","<a href=\"https://drive.google.com/file/d/1IeTnQ8yRptYu60Naaj7iZeBbJq-eOd0o/view?usp=sharing\" target=\"_blank\"><img src=\"https://drive.google.com/u/0/uc?id=1IeTnQ8yRptYu60Naaj7iZeBbJq-eOd0o&export=download\" width=\"80%\"></a>"]},{"cell_type":"code","metadata":{"id":"lcMlRIHTnGLC"},"source":["# TODO: 利用 html, css selector 來改變資料呈現 (ref. slide page 8)\n","\n","from IPython.display import HTML, display\n","\n","def set_css_in_cell_output():\n","  display(HTML(\"\"\"\n","\n","  \"\"\"))\n","\n","get_ipython().events.register('pre_run_cell', set_css_in_cell_output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0TaIfCPDgaSM"},"source":["pd.DataFrame(result_nuexin)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_65If7vFqNc1"},"source":["# TODO: 自己動手玩看看～\n","#        1. 讀取真實的範例資料 (火大-16, 全家-72, 有事-97, 難過-541)\n","#        2. 試試看讓每一頁呈現五筆資料就好\n","#        3. 改變 html 呈現：變更 keyword 欄位的顏色、字型或字體大小；調整所有欄位的對齊方式為置中。\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qD3t2lLWsM4o"},"source":["## 5-5: 要查詢單詞，也要查詢單個詞性\n","\n","請試著根據 5-3 所寫的 `query_a_word()`，寫一個 `query_a_token()`，讓這個函數既能查詢單一個word，也能查詢單一個pos。\n","\n","執行範例：\n","```python\n","# 找出所有詞目為「虐心」的token\n","query_a_token(token_value=\"虐心\", token_type=\"word\", window_size=10, show_pos=False, metadata=[\"forumName\", \"likeCount\"])\n","\n","# 找出所有詞性為「VA」的token\n","query_a_token(token_value=\"VA\", token_type=\"pos\", window_size=10, show_pos=False, metadata=[\"forumName\", \"likeCount\"])\n","```"]},{"cell_type":"code","metadata":{"id":"xUUPy6tmshfS"},"source":["# 注意: query_a_token() 跟剛才的 query_a_word() 只有兩個不同的小地方\n","#      1. query_a_token() 的前兩個參數變成 token_value 和 token_type\n","#      2. filter_a_word(word) 變成了 filter_a_token(token_value, token_type)\n","# TODO: 請大家完成 filter_a_token(token_value, token_type) 的內容\n","\n","def query_a_token(token_value, token_type, window_size=5, show_pos=False, metadata=[]):\n","\n","    results = []\n","\n","    for locator in filter_a_token(token_value, token_type):\n","        result = generate_concordance_line(locator, window_size, show_pos, metadata)\n","        results.append(result)\n","\n","    return results\n","\n","\n","def filter_a_token(token_value, token_type):\n","\n","    # 提示: 先判斷 token_type 為何，才知道要使用哪個 index\n","    pass"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l7HNy1EJ1FpZ"},"source":["# TODO: 自由時間，填入你想查的token吧，也嘗試看看修改不同參數的結果\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rpxAAJbx81X0"},"source":["## 5-6: 在查詢單個token的基礎上，加一點regular expression"]},{"cell_type":"markdown","metadata":{"id":"hNvi4Nd_dJXR"},"source":["請試著根據 5-5 所寫的 `query_a_token()`，寫一個 `query_a_regex_token()`，讓我們可以用 regular expression 查詢單一個word，也能查詢單一個pos。\n","\n","用處：\n","- 找出所有以「者」為後綴的詞。\n","- 找出所有以「老」為前綴的詞。\n","- 找出所有動詞性的詞。\n","\n","執行範例：\n","```python\n","# 找出所有以「者」為後綴的詞\n","query_a_regex_token(token_value=\".+者$\", token_type=\"word\", window_size=10, show_pos=False, metadata=[\"forumName\", \"likeCount\"])\n","\n","# 找出所有以「老」為前綴的詞\n","query_a_regex_token(token_value=\"^老.+\", token_type=\"word\", window_size=10, show_pos=False, metadata=[\"forumName\", \"likeCount\"])\n","\n","# 找出所有被標為動詞的詞\n","query_a_regex_token(token_value=\"^V.+\", token_type=\"pos\", window_size=10, show_pos=False, metadata=[\"forumName\", \"likeCount\"])\n","```"]},{"cell_type":"code","metadata":{"id":"kh_-C0WJ3H2j"},"source":["# 注意: query_a_regex_token() 跟剛才的 query_a_token() 只有一個不同點\n","#      1. filter_a_token(token_value, token_type) 變成了 filter_a_regex_token(token_value, token_type)\n","# TODO: 請大家完成 filter_a_regex_token(token_value, token_type) 的內容\n","\n","import re\n","\n","def query_a_regex_token(token_value, token_type, window_size=5, show_pos=False, metadata=[]):\n","\n","    results = []\n","\n","    for locator in filter_a_regex_token(token_value, token_type):\n","        result = generate_concordance_line(locator, window_size, show_pos, metadata)\n","        results.append(result)\n","\n","    return results\n","\n","\n","def filter_a_regex_token(token_value, token_type):\n","    pass\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hNwHu2Zy9iuw"},"source":["# TODO: 試著找看看所有以「者」為後綴的token\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z1cGbie4sfO3"},"source":["# TODO: 找出所有以「老」開頭的token\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HnlEZb24wMcE"},"source":["## 5-7: 限定某詞性下的某詞 (回家練習)\n","\n","在中文當中，一個詞目可能會有不同的詞性，像是「花」錢和茉莉「花」。請寫一個函數，限定某個詞性下的詞。"]},{"cell_type":"markdown","metadata":{"id":"CvlkvWY25EzT"},"source":["## 5-8: [進階] 搜尋多個詞並列的 Phrase query"]},{"cell_type":"markdown","metadata":{"id":"ZSNxR5e1OWXB"},"source":["目前前面所實作的 `query_a_word()`, `query_a_token()` 和 `query_a_regex_token()` 都只能搜索單一個token。\n","\n","在搜尋語料時，我們可能還會需要針對多個並列的 token 進行搜索，例如 `query_phrase([\"做\", \"一\", \"個\"])`。\n","\n","所以我們現在要開始實作多個token並列的情況。\n","\n","執行範例：\n","```python\n","# 找出所有 「做」「一」「個」的句子\n","\n","phrase = [\n","    {\"type\": \"word\", \"value\": \"做\"},\n","    {\"type\": \"word\", \"value\": \"一\"},\n","    {\"type\": \"word\", \"value\": \"個\"},\n","]\n","\n","query_phrase(tokens=phrase, window_size=10, show_pos=False, metadata=[\"forumName\", \"likeCount\"])\n","```"]},{"cell_type":"code","metadata":{"id":"BxuUnpxhObp6"},"source":["def query_phrase(tokens, window_size=5, show_pos=False, metadata=[]):\n","\n","    results = []\n","\n","    for locator in filter_phrase(tokens):\n","        result = generate_concordance_line_v2(locator, window_size, show_pos, metadata)\n","        results.append(result)\n","\n","    return results"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_c5idW8h5D9Y"},"source":["def filter_phrase(tokens):\n","\n","    results = []\n","    token_freqs = []\n","\n","    # 先比較傳進來的 list of tokens，哪一個 token 的出現次數最少 => 為了對搜尋做優化\n","    for token in tokens:\n","        if token[\"type\"] == \"word\":\n","            # 使用我們前面已經寫好的 word_freq 函數\n","            token_freq = word_freq(token[\"value\"])\n","\n","        elif token[\"type\"] == \"pos\":\n","            token_freq = 1000000000\n","            # token_freq = sum([pos_freq(pos) for pos in pos_index.keys() if re.match(token[\"value\"], pos)])\n","            # len(pos_index[token[\"value\"]])\n","        else:\n","            raise ValueError(\"token type只能是 word 或 pos\")\n","\n","        token_freqs.append(token_freq)\n","\n","    # 找出 token_freqs 最小的\n","    min_freq = min(token_freqs)\n","\n","    # 找出出現次數最少的 token 是的第幾個\n","    min_freq_idx = token_freqs.index(min_freq)\n","\n","    # 找出出現次數最少的 token value\n","    min_freq_token_value = tokens[min_freq_idx][\"value\"]\n","    \n","    # 出現次數最少的 token 的位置離tokens 最左邊的元素多遠?\n","    normalized_index = [i - min_freq_idx for i in range(len(tokens))]\n","\n","    # 從出現次數最少次的 token 開始找\n","    for a_idx, s_idx, t_idx in word_index[min_freq_token_value]:\n","        \n","        need_to_pass = False\n","        sentence = corpus[a_idx][\"text\"][s_idx]\n","\n","        for i in range(len(tokens)):\n","            if i != min_freq_idx:\n","                # 因為可能會超過句子邊界，所以使用 try...except...處理這種情況\n","                try:\n","                    if tokens[i][\"type\"] == \"word\":\n","                        if sentence[t_idx + (i - min_freq_idx)][tokens[i][\"type\"]] != tokens[i][\"value\"]:\n","                            need_to_pass = True\n","                            break\n","                    elif tokens[i][\"type\"] == \"pos\":\n","                        if not re.match(tokens[i][\"value\"], sentence[t_idx + (i - min_freq_idx)][tokens[i][\"type\"]]):\n","                            need_to_pass = True\n","                            break\n","\n","                except:\n","                    need_to_pass = True\n","                    break\n","        if need_to_pass:\n","            continue\n","\n","        results.append([a_idx, s_idx, [i + t_idx for i in normalized_index]])\n","    \n","    return results"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YMUV4JD7OiQh"},"source":["# 現在 locator 傳進來的東西是 [10, 2, [20, 21, 22]]\n","# 也就是說 t_idx 不再是單個整數，而是list of int\n","def generate_concordance_line_v2(locator, window_size, show_pos, metadata):\n","    a_idx = locator[0]\n","    s_idx = locator[1]\n","    t_idxs = locator[2]\n","\n","    sentence = corpus[a_idx]['text'][s_idx]\n","\n","    # 準備好每個元素\n","    each_concordance_line = {\n","        \"article_id\": a_idx,\n","        \"left\": \"\",\n","        \"keyword\": \"\",\n","        \"right\": \"\"\n","    }\n","\n","    # 需要哪些metadata，就把那些metadata裝進來\n","    for key in metadata:\n","        each_concordance_line[key] = corpus[a_idx][key]\n","\n","    # 判斷是否要顯示詞性\n","    if show_pos:\n","        each_concordance_line[\"keyword\"] = \" \".join([sentence[t_idx][\"word\"] + \"/\" + sentence[t_idx][\"pos\"] for t_idx in t_idxs])\n","    else:\n","        each_concordance_line[\"keyword\"] = \" \".join([sentence[t_idx][\"word\"] for t_idx in t_idxs])\n","\n","    # 安全邊界\n","    safe_left_bound = max(0, t_idxs[0] - window_size)\n","    safe_right_bound = min(len(sentence), t_idxs[-1] + window_size + 1)\n","\n","\n","    # 先處理處理關鍵字的左邊部分\n","    for token in sentence[safe_left_bound: t_idxs[0]]:\n","        if show_pos:\n","            each_concordance_line[\"left\"] += token[\"word\"] + \"/\" + token[\"pos\"]\n","        else:\n","            each_concordance_line[\"left\"] += token[\"word\"]\n","\n","    # 再處理處理關鍵字的右邊部分\n","    for token in sentence[t_idxs[-1] + 1: safe_right_bound]:\n","        if show_pos:\n","            each_concordance_line[\"right\"] += token[\"word\"] + \"/\" + token[\"pos\"]\n","        else:\n","            each_concordance_line[\"right\"] += token[\"word\"]\n","\n","    return each_concordance_line"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mNRFaqWH7PC9"},"source":["# TODO: 請找出所有 \"的\" \"動作\" 的句子\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eOyMqxWhSDfR"},"source":["## 5-9: 比較 `V+下來` 和 `V+下去`"]},{"cell_type":"code","metadata":{"id":"LW2OBwKLmxyY"},"source":["# TODO: 請找出所有 V + \"下來\" 的句子\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vRPQ2g_7tts5"},"source":["# TODO: 請找出所有 V + \"下去\" 的句子\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DEL940YKXwIj"},"source":["# TODO: 自由發揮看看\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yUoVn8NCtavb"},"source":["# Step 6: Collocation"]},{"cell_type":"markdown","metadata":{"id":"HCF6EelNtdKN"},"source":["![](https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20180904072708260-0799:9781316410899:12570tbl3_1.png?pub-status=live)"]},{"cell_type":"markdown","metadata":{"id":"-KY9DvRTuSiE"},"source":["![](https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20180904072708260-0799:9781316410899:12570tbl3_2.png?pub-status=live)"]},{"cell_type":"markdown","metadata":{"id":"yR0JSQNS1_1A"},"source":["各種Association measure:"]},{"cell_type":"markdown","metadata":{"id":"Ceyvv8-ztpAb"},"source":["![](https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20180904072708260-0799:9781316410899:12570tbl3_3.png?pub-status=live)"]},{"cell_type":"markdown","metadata":{"id":"JinhRCBf154N"},"source":["## 6-1: 看「造成」一詞右邊一格的Collocation\n","\n","右邊一格的意思就是 window size 為 1R (one 有時也能標為 +1)\n","\n","在這個練習我們將以 LogDice 這個 association measure 為例子。"]},{"cell_type":"code","metadata":{"id":"jppMaVhkuWyg"},"source":["# LogDice 算式中只出現 O11, R1, C1\n","\n","## 以 造成 + 困擾 為例\n","### O11 為 造成 + 困擾 的總數\n","### R1  為 造成 + X    的總數 ~ 先以造成的總數來看\n","### C1  為 X   + 困擾  的總數 ~ 先以困擾的總數來看\n","\n","# 先找出所有出現在「造成」後面一個的詞\n","\n","result = {}\n","\n","# 「造成」的詞頻\n","R1 = len(word_index['造成'])\n","\n","for a_idx, s_idx, w_idx in word_index['造成']:\n","    \n","    sentence_with_造成 = corpus[a_idx]['text'][s_idx]\n","\n","    # 跳過 造成 在句尾的情況\n","    if w_idx + 1 >= len(sentence_with_造成):\n","      continue\n","\n","    # word_1r 為在這句話中，出現在「造成」後面的那個詞\n","    word_1r = corpus[a_idx]['text'][s_idx][w_idx + 1]['word']\n","\n","    # 要是 word_1r 尚未出現在 result 之中，就初始化\n","    if word_1r not in result:\n","      result[word_1r] = {\"O11\": 1, \"C1\": len(word_index[word_1r]), \"R1\": R1}\n","    \n","    # 要是 word_1r 已經出現過了，那麼只要把他的 O11 加上 1 就好\n","    else:\n","      result[word_1r][\"O11\"] += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9NuKdKimwSgy"},"source":["result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y9ULOYHu036S"},"source":["result_df = pd.DataFrame.from_dict(result, orient='index')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U77Dkh0sx6z1"},"source":["#TODO: 寫一個運算 log_dice 的函數\n","import numpy as np\n","def log_dice(O11, R1, C1):\n","  return 14 + np.log(2 * O11 / (R1 + C1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OtEFTRu-1CRk"},"source":["result_df['log_dice'] = result_df.apply(lambda x: log_dice(x['O11'], x['R1'], x['C1']), axis=1)\n","result_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kXb0AHGOkSAM"},"source":["# TODO: 找自己有興趣的詞來看看"],"execution_count":null,"outputs":[]}]}